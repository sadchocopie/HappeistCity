{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options \n",
    "import selenium.webdriver.support.ui as ui\n",
    "import time\n",
    "chrome_options = Options()  \n",
    "chrome_options.add_argument(\"--headless\")\n",
    "br = webdriver.Chrome(chrome_options=chrome_options, executable_path=r'./chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: code takes more than an hour to run since we have to wait until every\n",
    "# page's Javascript content loads. That takes around 1-2 seconds normally, but\n",
    "# sometimes may take one second longer than that, causing the program to crash.\n",
    "# We use 5 seconds just in case, to avoid any possible hangups in the process.\n",
    "\n",
    "# Scrapes median income, unemployment rate, and mean commute times of every city\n",
    "def scraping_cities(city, row):\n",
    "  \n",
    "    br.get(\"https://factfinder.census.gov/faces/nav/jsf/pages/community_facts.xhtml\")\n",
    "    wait = ui.WebDriverWait(br,15)\n",
    "    time.sleep(2)\n",
    "    # Types search terms for a city\n",
    "    element = wait.until(lambda br:br.find_element_by_id('cfsearchtextbox'))\n",
    "    element.clear()\n",
    "    element.send_keys(city)\n",
    "\n",
    "    # Submits form\n",
    "    element =  wait.until(lambda br: br.find_element_by_xpath('//*[@id=\"communityfactssubmit\"]'))\n",
    "    element.click()\n",
    "\n",
    "    # Clicking the income tab\n",
    "    time.sleep(2.5)\n",
    "    element = wait.until(lambda br:br.find_element_by_xpath('//*[@id=\"leftnav\"]/a[7]'))\n",
    "    element.click()\n",
    "\n",
    "    # Getting table link\n",
    "    time.sleep(2.5)\n",
    "    element = wait.until(lambda br:br.find_element_by_xpath('//*[@id=\"cf-content\"]/div[2]/div[1]/ul[1]/li[1]/div/a'))\n",
    "    href = element.get_attribute('href')\n",
    "    br.get(href)\n",
    "\n",
    "    #\n",
    "    for i in range(2, 9):\n",
    "        time.sleep(5)\n",
    "            \n",
    "        # Append unemployment rate\n",
    "        element = wait.until(lambda br:br.find_element_by_xpath('//*[@id=\"data\"]/tbody/tr[11]/td[3]'))\n",
    "        unemploymentDF.iloc[row, i-2] = element.text\n",
    "        \n",
    "        # Append commute time rate\n",
    "        element = wait.until(lambda br:br.find_element_by_xpath('//*[@id=\"data\"]/tbody/tr[33]/td[1]'))\n",
    "        commuteDF.iloc[row, i-2] = element.text\n",
    "        \n",
    "        # Append median income data\n",
    "        element = wait.until(lambda br:br.find_element_by_xpath('//*[@id=\"data\"]/tbody/tr[79]/td[1]'))\n",
    "        incomeDF.iloc[row, i-2] = element.text\n",
    "        \n",
    "        # Stop from getting nonexistent element\n",
    "        if i == 8:\n",
    "            break\n",
    "        \n",
    "        # Get previous year\n",
    "        element = wait.until(lambda br:br.find_element_by_xpath('//*[@id=\"year_selector_content\"]/ul/li['+ str(i) +']/a'))\n",
    "        element.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The next cell is where we get the list of the cities that we are working with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birmingham, AL 0\n",
      "Montgomery, AL 1\n",
      "Anchorage, AK 2\n",
      "Juneau, AK 3\n",
      "Phoenix, AZ 4\n",
      "Tucson, AZ 5\n",
      "Little Rock, AR 6\n",
      "Fort Smith, AR 7\n",
      "San Diego, CA 8\n",
      "Los Angeles, CA 9\n",
      "Sacramento, CA 10\n",
      "Denver, CO 11\n",
      "Colorado Springs, CO 12\n",
      "Aurora, CO 13\n",
      "Bridgeport, CT 14\n",
      "Hartford, CT 15\n",
      "Dover, DE 16\n",
      "Wilmington, DE 17\n",
      "Jacksonville, FL 18\n",
      "Miami, FL 19\n",
      "Tallahassee, FL 20\n",
      "Atlanta, GA 21\n",
      "Savannah, GA 22\n",
      "Honolulu, HI 23\n",
      "Kauai, HI 24\n",
      "Maui, HI 25\n",
      "Boise, ID 26\n",
      "Meridian, ID 27\n",
      "Chicago, IL 28\n",
      "Springfield, IL 29\n",
      "Fort Wayne, IN 30\n",
      "Indianapolis, IN 31\n",
      "Cedar Rapids, IA 32\n",
      "Des Moines, IA 33\n",
      "Topeka, KS 34\n",
      "Wichita, KS 35\n",
      "Frankfort, KY 36\n",
      "Louisville, KY 37\n",
      "Baton Rouge, LA 38\n",
      "New Orleans, LA 39\n",
      "Augusta, ME 40\n",
      "Portland, ME 41\n",
      "Baltimore, MD 42\n",
      "Annapolis, MD 43\n",
      "Boston, MA 44\n",
      "Worcester, MA 45\n",
      "Detroit, MA 46\n",
      "Lansing, MA 47\n",
      "Minneapolis, MN 48\n",
      "Saint Paul, MN 49\n",
      "Jackson, MS 50\n",
      "Gulfport, MS 51\n",
      "Kansas City, MO 52\n",
      "Jefferson City, MO 53\n",
      "Billings, MT 54\n",
      "Helena, MT 55\n",
      "Lincoln, NE 56\n",
      "Omaha, NE 57\n",
      "Carson City, NV 58\n",
      "Las Vegas, NV 59\n",
      "Reno, NV 60\n",
      "Concord, NH 61\n",
      "Manchester, NH 62\n",
      "Newark, NJ 63\n",
      "Trenton, NJ 64\n",
      "Albuquerque, NM 65\n",
      "Santa Fe, NM 66\n",
      "Albany, NY 67\n",
      "New York City, NY 68\n",
      "Charlotte, NC 69\n",
      "Raleigh, NC 70\n",
      "Bismarck, ND 71\n",
      "Fargo, ND 72\n",
      "Columbus, OH 73\n",
      "Cleveland, OH 74\n",
      "Oklahoma City, OK 75\n",
      "Tulsa, OK 76\n",
      "Portland, OR 77\n",
      "Salem, OR 78\n",
      "Harrisburg, PA 79\n",
      "Philadelphia, PA 80\n",
      "Providence, RI 81\n",
      "Warwick, RI 82\n",
      "Charleston, SC 83\n",
      "Columbia, SC 84\n",
      "Pierre, SD 85\n",
      "Sioux Falls, SD 86\n",
      "Nashville, TN 87\n",
      "Memphis, TN 88\n",
      "Austin, TX 89\n",
      "El Paso, TX 90\n",
      "Houston, TX 91\n",
      "Salt Lake city, UT 92\n",
      "West Valley City, UT 93\n",
      "Burlington, VT 94\n",
      "Montpelier, VT 95\n",
      "Richmond, VA 96\n",
      "Virginia Beach, VA 97\n",
      "Olympia, WA 98\n",
      "Seattle, WA 99\n",
      "Charleston, WV 100\n",
      "Huntington, WV 101\n",
      "Madison, WI 102\n",
      "Milwaukee, WI 103\n",
      "Casper, WY 104\n",
      "Cheyenne, WY 105\n"
     ]
    }
   ],
   "source": [
    "cities = [line.rstrip('\\n\\r') for line in open('./cities.txt')]\n",
    "\n",
    "# Setting up the column names for each data frame\n",
    "incomeDF = pd.DataFrame(columns=[\"City\", \"Median Income 2016\", \"Median Income 2015\", \"Median Income 2014\", \"Median Income 2013\",\n",
    "                  \"Median Income 2012\", \"Median Income 2011\", \"Median Income 2010\"])\n",
    "\n",
    "unemploymentDF = pd.DataFrame(columns=[\"City\", \"Unemployment Rate 2016\", \"Unemployment Rate 2015\", \"Unemployment Rate 2014\", \n",
    "                                       \"Unemployment Rate 2013\", \"Unemployment Rate 2012\", \"Unemployment Rate 2011\", \n",
    "                                       \"Unemployment Rate 2010\"])\n",
    "\n",
    "commuteDF = pd.DataFrame(columns=[\"City\", \"Mean Commute Time 2016\", \"Mean Commute Time 2015\", \"Mean Commute Time 2014\", \n",
    "                                  \"Mean Commute Time 2013\", \"Mean Commute Time 2012\", \"Mean Commute Time 2011\", \n",
    "                                  \"Mean Commute Time 2010\"])\n",
    "\n",
    "# Set the amount of rows per data frame\n",
    "data = pd.DataFrame({\"City\": range(len(cities))})\n",
    "incomeDF = incomeDF.append(data)\n",
    "unemploymentDF = unemploymentDF.append(data)\n",
    "commuteDF = commuteDF.append(data)\n",
    "\n",
    "# Input the name of a city per row in each data frame\n",
    "for i, row in incomeDF.iterrows():\n",
    "    row.loc['City'] = cities[i]\n",
    "    \n",
    "for i, row in unemploymentDF.iterrows():\n",
    "    row.loc['City'] = cities[i]\n",
    "    \n",
    "for i, row in commuteDF.iterrows():\n",
    "    row.loc['City'] = cities[i]\n",
    "\n",
    "\n",
    "# Reverse the column order (ie 2010 to 2016)\n",
    "incomeDF = incomeDF.iloc[:, ::-1]\n",
    "unemploymentDF = unemploymentDF.iloc[:, ::-1]\n",
    "commuteDF = commuteDF.iloc[:, ::-1]\n",
    "\n",
    "for i, city in enumerate(cities):\n",
    "    scraping_cities(city, i)\n",
    "    print(city + \" \" + str(i)) # Done to see what city we're currently scraping\n",
    "\n",
    "# Setting the \"City\" as the index column for all dataframes\n",
    "incomeDF = incomeDF.set_index('City')\n",
    "unemploymentDF = unemploymentDF.set_index('City')\n",
    "commuteDF = commuteDF.set_index('City')\n",
    "\n",
    "# Close the webdriver instance\n",
    "br.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating CSV files per dataframe\n",
    "incomeDF = incomeDF.reset_index()\n",
    "incomeDF.to_csv('cities_median_income.csv', encoding='utf-8', index=False)\n",
    "\n",
    "unemploymentDF = unemploymentDF.reset_index()\n",
    "unemploymentDF.to_csv('cities_unemployment_rate.csv', encoding='utf-8', index=False)\n",
    "\n",
    "commuteDF = commuteDF.reset_index()\n",
    "commuteDF.to_csv('cities_mean_commute_time.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
